{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMg19w0IHcEyzmpmi7DfsHs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"id":"pSpyK0H3EPp0","executionInfo":{"status":"error","timestamp":1737399308177,"user_tz":-60,"elapsed":11833,"user":{"displayName":"kirbix 94","userId":"13329749952414277843"}},"outputId":"7a0d6342-f0fb-4da0-bcf8-6863e10413a6"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'dataset_path'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-f8a561fa76d5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Carga de datos de entrenamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Carga imágenes del directorio especificado y las convierte en lotes con las transformaciones definidas.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m train_data = train_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Directorio raíz de los datos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Redimensiona todas las imágenes a 150x150 píxeles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset_path'"]}],"source":["# Importación de librerías necesarias\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import EarlyStopping\n","import numpy as np\n","from tensorflow.keras.preprocessing import image\n","\n","# 1. Preparación de los datos\n","# Ruta a los conjuntos de datos de imágenes\n","# Aquí se debe especificar la ubicación del dataset. Este dataset debe estar organizado en subcarpetas\n","# donde cada subcarpeta representa una clase (por ejemplo, /dogs y /cats).\n","data_dir = \"dataset_path\"  # Reemplaza con la ruta a tu dataset\n","\n","# Generador de datos con aumentación\n","# ImageDataGenerator permite realizar aumentación de datos para prevenir el sobreajuste.\n","# Rescale normaliza los valores de píxeles al rango [0, 1].\n","# Otros parámetros como rotation_range, zoom_range y horizontal_flip aplican transformaciones aleatorias.\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,  # Escala los valores de los píxeles al rango [0, 1]\n","    rotation_range=20,  # Rotación aleatoria en un rango de 20 grados\n","    width_shift_range=0.2,  # Desplazamiento horizontal\n","    height_shift_range=0.2,  # Desplazamiento vertical\n","    shear_range=0.2,  # Transformación en cizalla\n","    zoom_range=0.2,  # Zoom aleatorio\n","    horizontal_flip=True,  # Volteo horizontal\n","    validation_split=0.2  # Divide los datos en 80% entrenamiento y 20% validación\n",")\n","\n","# Carga de datos de entrenamiento\n","# Carga imágenes del directorio especificado y las convierte en lotes con las transformaciones definidas.\n","train_data = train_datagen.flow_from_directory(\n","    data_dir,  # Directorio raíz de los datos\n","    target_size=(150, 150),  # Redimensiona todas las imágenes a 150x150 píxeles\n","    batch_size=32,  # Tamaño del lote\n","    class_mode='binary',  # Tarea de clasificación binaria (perro/gato)\n","    subset='training'  # Subconjunto de entrenamiento\n",")\n","\n","# Carga de datos de validación\n","# Similar a train_data, pero se usa el subconjunto de validación.\n","validation_data = train_datagen.flow_from_directory(\n","    data_dir,\n","    target_size=(150, 150),\n","    batch_size=32,\n","    class_mode='binary',\n","    subset='validation'\n",")\n","\n","# 2. Diseño del modelo CNN\n","# Se crea una red neuronal convolucional (CNN) con 3 bloques de capas convolucionales y de agrupación.\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),  # 32 filtros de 3x3, activación ReLU\n","    MaxPooling2D(pool_size=(2, 2)),  # Agrupación máxima 2x2 para reducir dimensiones\n","\n","    Conv2D(64, (3, 3), activation='relu'),  # Segundo bloque convolucional\n","    MaxPooling2D(pool_size=(2, 2)),\n","\n","    Conv2D(128, (3, 3), activation='relu'),  # Tercer bloque convolucional\n","    MaxPooling2D(pool_size=(2, 2)),\n","\n","    Flatten(),  # Aplana el tensor 3D en un vector 1D para las capas densas\n","    Dense(128, activation='relu'),  # Capa completamente conectada con 128 neuronas\n","    Dropout(0.5),  # Apaga aleatoriamente el 50% de las neuronas para prevenir sobreajuste\n","    Dense(1, activation='sigmoid')  # Capa de salida con activación sigmoidal (probabilidad)\n","])\n","\n","# 3. Compilación del modelo\n","# Se configura el modelo con un optimizador (Adam), una función de pérdida adecuada y una métrica.\n","model.compile(\n","    optimizer='adam',  # Optimizador Adam\n","    loss='binary_crossentropy',  # Función de pérdida para clasificación binaria\n","    metrics=['accuracy']  # Métrica de precisión\n",")\n","\n","# 4. Entrenamiento del modelo\n","# EarlyStopping detiene el entrenamiento si la pérdida de validación no mejora durante 5 épocas consecutivas.\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","# Entrenamos el modelo con los datos de entrenamiento y validación.\n","history = model.fit(\n","    train_data,  # Datos de entrenamiento\n","    validation_data=validation_data,  # Datos de validación\n","    epochs=20,  # Número máximo de épocas\n","    callbacks=[early_stopping]  # Callback para detener entrenamiento temprano\n",")\n","\n","# 5. Evaluación del modelo\n","# Evalúa el modelo en el conjunto de validación y muestra la precisión.\n","eval_results = model.evaluate(validation_data)\n","print(f\"\\nPrecisión en validación: {eval_results[1] * 100:.2f}%\")\n","\n","# 6. Guardar el modelo\n","# Guarda el modelo entrenado en un archivo .h5 para reutilizarlo posteriormente.\n","model.save(\"cnn_model.h5\")\n","\n","# 7. Cargar el modelo para predicciones\n","# Se carga el modelo previamente guardado.\n","loaded_model = tf.keras.models.load_model(\"cnn_model.h5\")\n","\n","# Predicción de nuevas imágenes\n","# Esta función permite cargar una imagen y predecir si es un perro o un gato.\n","def predict_image(img_path):\n","    # Carga la imagen y la redimensiona al tamaño requerido por el modelo\n","    img = image.load_img(img_path, target_size=(150, 150))\n","    img_array = image.img_to_array(img) / 255.0  # Normaliza la imagen\n","    img_array = np.expand_dims(img_array, axis=0)  # Agrega una dimensión para el lote\n","\n","    # Realiza la predicción\n","    prediction = loaded_model.predict(img_array)\n","    if prediction[0] > 0.5:\n","        print(f\"La imagen es un gato (Confianza: {prediction[0][0] * 100:.2f}%)\")\n","    else:\n","        print(f\"La imagen es un perro (Confianza: {(1 - prediction[0][0]) * 100:.2f}%)\")\n","\n","# Ejemplo de uso\n","# Llama a la función predict_image pasando la ruta de una nueva imagen.\n","predict_image(\"path_to_new_image.jpg\")  # Reemplaza con la ruta de la imagen para predecir\n"]}]}